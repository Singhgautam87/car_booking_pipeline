pipeline {
    agent any

    environment {
        COMPOSE_FILE = "docker-compose.yml"
    }
    
    stages {
        stage("Checkout Code") {
            steps {
                checkout scm
                sh "ls -la"
            }
        }
        
        stage('Cleanup') {
            steps {
                sh '''
                    # Stop GE if running
                    docker stop great_expectations 2>/dev/null || true
                    
                    # Remove all containers except GE
                    docker-compose down --remove-orphans
                    
                    # Clean conflicting containers
                    docker ps -a | grep -E "postgres|mysql|kafka|zookeeper|spark|minio|kafka-ui" | awk '{print $1}' | xargs -r docker rm -f 2>/dev/null || true
                '''
            }
        }
        
        stage('Start Containers') {
            steps {
                sh '''
                    # Start or reuse GE
                    if docker ps -a -q -f name=^great_expectations$ | grep -q .; then
                        docker start great_expectations || docker-compose up -d great_expectations
                    else
                        docker-compose up -d great_expectations
                    fi
                    
                    sleep 10
                    docker exec great_expectations python -c "import great_expectations"
                    
                    # Start OTHER services (EXCLUDE great_expectations to avoid conflict)
                    docker-compose up -d postgres mysql kafka zookeeper minio kafka-ui spark-master
                    sleep 20
                    docker-compose ps
                '''
            }
        }

        stage("Kafka Producer") {
            steps {
                sh '''
                    sleep 10
                    docker exec kafka kafka-topics --create --if-not-exists --topic car-bookings --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 || true
                    docker exec kafka python /kafka/producer.py
                '''
            }
        }

        stage("Spark Streaming") {
            steps {
                sh "docker exec spark-master spark-submit /opt/spark-apps/ingest_stream.py"
            }
        }

        stage("Transform & Merge") {
            steps {
                sh '''
                    docker exec spark-master spark-submit /opt/spark-apps/transform_booking.py
                    docker exec spark-master spark-submit /opt/spark-apps/transform_customer.py
                    docker exec spark-master spark-submit /opt/spark-apps/merge_customer_booking.py
                    docker exec spark-master spark-submit /opt/spark-apps/write_to_postgres.py
                '''
            }
        }

        stage('Data Quality') {
            steps {
                sh '''
                    docker exec great_expectations python /ge/run_checkpoint.py
                    echo "✅ Data quality checks passed"
                '''
            }
        }

        stage("Load MySQL") {
            steps {
                sh "docker exec spark-master spark-submit /opt/spark-apps/write_to_mysql.py"
            }
        }
    }

    post {
        success {
            echo "✅ Pipeline completed"
        }
        failure {
            echo "❌ Pipeline failed"
            sh "docker-compose ps"
        }
    }
}