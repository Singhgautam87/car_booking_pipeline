pipeline {
    agent any

    environment {
        COMPOSE_FILE = "docker-compose.yml"
    }
    
    stages {
        stage("Checkout Code") {
            steps {
                checkout scm
                sh "echo 'Code checked out successfully' && ls -la"
            }
        }
        
        stage('Start Containers') {
            steps {
                sh '''
                    echo "üîç Checking container status..."
            
                    # Great Expectations check karo
                    if docker ps --format '{{.Names}}' | grep -q '^great_expectations$'; then
                        echo "‚úÖ Great Expectations container already running - reusing it"
                    else
                        echo "üöÄ Starting Great Expectations container..."
                        docker-compose up -d great_expectations
                        sleep 5
                    fi
            
                    # Baaki containers start karo (no recreate)
                    echo "üöÄ Starting other containers..."
                    docker-compose up -d --no-recreate
            
                    sleep 10
            
                    echo "üìã Container Status:"
                    docker-compose ps
                '''
            }
      }

        stage("Kafka Producer") {
            steps {
                sh "docker exec car-booking-pipeline-kafka-1 python /kafka/producer.py"
            }
        }

        stage("Spark Streaming Ingest") {
            steps {
                sh "docker exec spark spark-submit /opt/spark-apps/ingest_stream.py"
            }
        }

        stage("Transform & Merge") {
            steps {
                sh """
                docker exec spark spark-submit /opt/spark-apps/transform_booking.py
                docker exec spark spark-submit /opt/spark-apps/transform_customer.py
                docker exec spark spark-submit /opt/spark-apps/merge_customer_booking.py
                docker exec spark spark-submit /opt/spark-apps/write_to_postgres.py
                """
            }
        }

        stage('Data Quality - Great Expectations') {
            steps {
                sh '''
                    echo "üìä Running Great Expectations validations..."
            
                    # Existing container mein command run karo
                    docker exec great_expectations python /ge/run_checkpoint.py
            
                    if [ $? -eq 0 ]; then
                        echo "‚úÖ Data quality checks PASSED"
                    else
                        echo "‚ùå Data quality checks FAILED"
                        exit 1
                    fi
                '''
            }
        }
        stage("Load MySQL (Final)") {
            steps {
                sh "docker exec spark spark-submit /opt/spark-apps/write_to_mysql.py"
            }
        }
    }

    post {
        success {
            echo "‚úÖ PIPELINE COMPLETED SUCCESSFULLY"
        }
        failure {
            echo "‚ùå PIPELINE FAILED ‚Äì CHECK LOGS"
        }
    }
}