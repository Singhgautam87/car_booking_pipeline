pipeline {
    agent any

    environment {
        COMPOSE_FILE = "docker-compose.yml"
    }
    
    stages {
        stage("Checkout Code") {
            steps {
                checkout scm
                sh "ls -la"
            }
        }
        
        stage('Cleanup') {
            steps {
                sh '''
                    # Stop all containers
                    docker-compose down --remove-orphans
            
                    # Clean up any remaining containers
                    docker ps -a | grep -E "postgres|mysql|kafka|zookeeper|spark|minio|kafka-ui|great_expectations" | awk '{print $1}' | xargs -r docker rm -f || true
                '''
            }
        }
        stage('Start Containers') {
            steps {
                sh '''
                    # Start all containers including great_expectations
                    docker-compose up -d postgres mysql kafka zookeeper minio kafka-ui spark great_expectations
            
                    # Wait longer for Kafka to initialize
                    sleep 40
            
                    # Verify Kafka is ready
                    echo "Checking Kafka readiness..."
                    docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092 || echo "Kafka still initializing..."
            
                    # Show container status
                    docker-compose ps
                '''
            }
        }          

        stage('Kafka Producer') {
            steps {
                sh 'sleep 10'
                sh 'docker exec kafka kafka-topics --create --if-not-exists --topic car-bookings --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1'
                sh 'docker exec great_expectations pip install kafka-python'
                sh 'docker cp kafka/producer.py great_expectations:/tmp/producer.py'
                sh 'docker exec great_expectations python /tmp/producer.py'
            }  
        }

        stage("Spark Streaming") {
            steps {
                sh "docker exec spark-master spark-submit /opt/spark-apps/ingest_stream.py"
            }
        }

        stage("Transform & Merge") {
            steps {
                sh '''
                    docker exec spark-master spark-submit /opt/spark-apps/transform_booking.py
                    docker exec spark-master spark-submit /opt/spark-apps/transform_customer.py
                    docker exec spark-master spark-submit /opt/spark-apps/merge_customer_booking.py
                    docker exec spark-master spark-submit /opt/spark-apps/write_to_postgres.py
                '''
            }
        }

        stage('Data Quality') {
            steps {
                sh '''
                    docker exec great_expectations python /ge/run_checkpoint.py
                    echo "✅ Data quality checks passed"
                '''
            }
        }

        stage("Load MySQL") {
            steps {
                sh "docker exec spark-master spark-submit /opt/spark-apps/write_to_mysql.py"
            }
        }
    }

    post {
        success {
            echo "✅ Pipeline completed"
        }
        failure {
            echo "❌ Pipeline failed"
            sh "docker-compose ps"
        }
    }
}
